{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files, set up folder, put files into folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data: ./train.tsv\n",
    "# test data:     ./test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 3, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m test_tsv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_converted.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Convert both files\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m convert_csv_to_tsv(train_csv, train_tsv)\n\u001b[1;32m     37\u001b[0m convert_csv_to_tsv(test_csv, test_tsv)\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36mconvert_csv_to_tsv\u001b[0;34m(input_csv, output_tsv)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_csv_to_tsv\u001b[39m(input_csv, output_tsv):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - Assignment 2/csv, Code files/train_converted.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Print column names and first few rows to confirm structure\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 3, saw 8\n"
     ]
    }
   ],
   "source": [
    "# For files with 3 cols. Label, title, and review. Filtering out just the label and review.\n",
    "# Function to process a CSV file and convert it to TSV using review column\n",
    "def convert_csv_to_tsv(input_csv, output_tsv):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv('/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - Assignment 2/csv, Code files/train_converted.tsv')\n",
    "\n",
    "    # Print column names and first few rows to confirm structure\n",
    "    print(f\"\\nProcessing {input_csv}\")\n",
    "    print(\"Column names:\", df.columns.tolist())\n",
    "    print(\"First few rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Keep only the label (column 0) and review (column 2), drop title (column 1)\n",
    "    df = df.iloc[:, [0, 2]]\n",
    "\n",
    "    # Map the labels: 2 -> 1 (positive), 1 -> 0 (negative)\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].map({2: 1, 1: 0})\n",
    "\n",
    "    # Rename the columns to match train.tsv format\n",
    "    df.columns = ['label', 'review']\n",
    "\n",
    "    # Save as TSV file with tab separator, without index\n",
    "    df.to_csv(output_tsv, sep='\\t', index=False, header=True)\n",
    "\n",
    "    print(f\"Conversion complete! File saved as {output_tsv}\")\n",
    "    print(\"First few rows of the converted data:\")\n",
    "    print(df.head())\n",
    "\n",
    "# Paths to your files (adjust if needed)\n",
    "train_csv = '/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - 2/csv, Code files/gittrain.csv'\n",
    "test_csv = '/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - 2/csv, Code files/gittest.csv'\n",
    "train_tsv = 'train_converted.tsv'\n",
    "test_tsv = 'test_converted.tsv'\n",
    "\n",
    "# Convert both files\n",
    "convert_csv_to_tsv(train_csv, train_tsv)\n",
    "convert_csv_to_tsv(test_csv, test_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label                                             review\n",
      "0            1  I'm reading a lot of reviews saying that this ...\n",
      "1            1  This soundtrack is my favorite music of all ti...\n",
      "2            1  I truly like this soundtrack and I enjoy video...\n",
      "3            1  If you've played the game, you know how divine...\n",
      "4            1  I am quite sure any of you actually taking the...\n",
      "...        ...                                                ...\n",
      "3599994      0  The high chair looks great when it first comes...\n",
      "3599995      0  I have used this highchair for 2 kids now and ...\n",
      "3599996      0  We have a small house, and really wanted two o...\n",
      "3599997      0  not sure what this book is supposed to be. It ...\n",
      "3599998      1  I agree that every American should read this b...\n",
      "\n",
      "[3599999 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - Assignment 2/csv, Code files/train_converted.tsv', sep = '\\t')\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Ignore, Trial for a .csv file downloaded fro github.....\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - 2/csv, Code files/gittrain.csv')\n",
    "\n",
    "# Print the first few rows and column names to inspect the data\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Assuming the first column is the label and second is the review text\n",
    "# Adjust these based on what you see in the column names printed above\n",
    "label_col = df.columns[0]  # First column\n",
    "review_col = df.columns[1] # Second column\n",
    "\n",
    "# Map the labels: 2 -> 1 (positive) and 1 -> 0 (negative)\n",
    "# This assumes 2 is positive and 1 is negative - verify this from the sample\n",
    "df[label_col] = df[label_col].map({2: 1, 1: 0})\n",
    "\n",
    "# Rename columns to match train.tsv expected format\n",
    "df = df.rename(columns={label_col: 'label', review_col: 'review'})\n",
    "\n",
    "# Ensure the columns are in the right order (label first, then review)\n",
    "df = df[['label', 'review']]\n",
    "\n",
    "# Save as TSV file with tab separator, without index\n",
    "df.to_csv('train_converted.tsv', sep='\\t', index=False, header=True)\n",
    "\n",
    "print(\"Conversion complete! File saved as 'train_converted.tsv'\")\n",
    "print(\"First few rows of the converted data:\")\n",
    "print(df.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 2879999\n",
      "validation set size: 720000\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8 # 80% for training, 20% for validation\n",
    "random_seed = 100\n",
    "\n",
    "train_dataframe = dataframe.sample(frac=train_ratio, random_state=random_seed)\n",
    "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
    "print('training set size:', len(train_dataframe))\n",
    "print('validation set size:', len(valid_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                             review\n",
      "0           1  Despite the fact that I have only played a sma...\n",
      "1           0  I bought this charger in Jul 2003 and it worke...\n",
      "2           1  Check out Maha Energy's website. Their Powerex...\n",
      "3           1  Reviewed quite a bit of the combo players and ...\n",
      "4           0  I also began having the incorrect disc problem...\n",
      "...       ...                                                ...\n",
      "399994      0  We bought this Thomas for our son who is a hug...\n",
      "399995      0  My son recieved this as a birthday gift 2 mont...\n",
      "399996      0  I bought this toy for my son who loves the \"Th...\n",
      "399997      1  This is a compilation of a wide range of Mitfo...\n",
      "399998      0  This DVD will be a disappointment if you get i...\n",
      "\n",
      "[399999 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dataframe = pd.read_csv('/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - Assignment 2/csv, Code files/gittest_converted.tsv', sep = '\\t')\n",
    "print (test_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the trivial baseline: predict the majority label of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1440465, 0: 1439534})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_dataframe['label'])                          ## Counts no. of 1's and 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority guess accuracy: 0.49935277777777776\n"
     ]
    }
   ],
   "source": [
    "# Looks like label 1 has slightly more counts than label 0 in training data\n",
    "# So the 'majority guess' prediction is an array filled with 1s\n",
    "majority_guess_pred = [1 for i in range(len(valid_dataframe))]\n",
    "accuracy = accuracy_score(valid_dataframe['label'], majority_guess_pred)\n",
    "print ('Majority guess accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: write out prediction values into a csv format file             '''Important'''\n",
    "# params:\n",
    "#     df: dataframe, where each row is a test example, with column 'id' as data id\n",
    "#     pred: a list or 1-d array of prediction values\n",
    "#     filepath: the output file path\n",
    "# return:\n",
    "#     None\n",
    "\n",
    "def write_test_prediction(df, pred, filepath):\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        outfile.write('{},{}\\n'.format('id', 'label'))\n",
    "        for index, row in df.iterrows():\n",
    "            outfile.write('{},{}\\n'.format(row['id'], pred[index]))\n",
    "    print (len(df), 'predictions are written to', filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority_guess_pred_test = [1 for i in range(len(test_dataframe))]\n",
    "# write_test_prediction(test_dataframe, majority_guess_pred_test, './majority_guess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use all unigrams from training data as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(binary=True, max_df=0.95, min_df=2, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(binary=True, max_df=0.95, min_df=2, ngram_range=(1, 2))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(binary=True, max_df=0.95, min_df=2, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), max_df=0.95, min_df=2, binary=True)\n",
    "vectorizer.fit(train_dataframe['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore, I was just testing\n",
    "#train_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract feature vectors for training, validation, and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2879999, 6062265)\n",
      "(720000, 6062265)\n",
      "(399999, 6062265)\n"
     ]
    }
   ],
   "source": [
    "# Count vectorizer\n",
    "train_X = vectorizer.transform(train_dataframe['review'])\n",
    "valid_X = vectorizer.transform(valid_dataframe['review'])\n",
    "test_X = vectorizer.transform(test_dataframe['review'])\n",
    "print (train_X.shape)\n",
    "print (valid_X.shape)\n",
    "print (test_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Using TFIDF vectorizer instead of count vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.95, min_df=2)\n",
    "vectorizer.fit(train_dataframe['review'])\n",
    "\n",
    "train_X = vectorizer.transform(train_dataframe['review'])\n",
    "valid_X = vectorizer.transform(valid_dataframe['review'])\n",
    "test_X = vectorizer.transform(test_dataframe['review'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2879999,)\n",
      "(720000,)\n"
     ]
    }
   ],
   "source": [
    "train_y = train_dataframe['label'].to_numpy()\n",
    "valid_y = valid_dataframe['label'].to_numpy()\n",
    "print (train_y.shape)\n",
    "print (valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use chi-square statistic to select a subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_features_to_select = 5000\n",
    "feature_selector = SelectKBest(score_func = chi2, k = num_features_to_select)\n",
    "feature_selector.fit(train_X, train_y)\n",
    "\n",
    "# feature names\n",
    "all_features = [feature for feature, index in sorted(vectorizer.vocabulary_.items(), key = lambda x: x[1])]\n",
    "selected_features = feature_selector.get_feature_names_out(input_features = all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Chatgpt's PMI:\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Compute word frequencies\n",
    "def get_word_frequencies(dataframe):\n",
    "    word_freq = defaultdict(int)\n",
    "    total_words = 0\n",
    "    for review in dataframe['review']:\n",
    "        words = review.split()\n",
    "        total_words += len(words)\n",
    "        for word in words:\n",
    "            word_freq[word] += 1\n",
    "    return word_freq, total_words\n",
    "\n",
    "# Compute class-specific word frequencies\n",
    "def get_class_word_frequencies(dataframe, label):\n",
    "    word_freq = defaultdict(int)\n",
    "    total_words = 0\n",
    "    for _, row in dataframe.iterrows():\n",
    "        if row['label'] == label:\n",
    "            words = row['review'].split()\n",
    "            total_words += len(words)\n",
    "            for word in words:\n",
    "                word_freq[word] += 1\n",
    "    return word_freq, total_words\n",
    "\n",
    "# Compute PMI for each word\n",
    "def compute_pmi(train_dataframe, num_features_to_select):\n",
    "    word_freq, total_words = get_word_frequencies(train_dataframe)\n",
    "    pos_word_freq, total_pos_words = get_class_word_frequencies(train_dataframe, 1)\n",
    "    neg_word_freq, total_neg_words = get_class_word_frequencies(train_dataframe, 0)\n",
    "\n",
    "    p_word = {word: freq / total_words for word, freq in word_freq.items()}\n",
    "\n",
    "    pmi_scores = {}\n",
    "\n",
    "    for word in word_freq:\n",
    "        if word in pos_word_freq and word in neg_word_freq:  # Ensure word exists in both classes\n",
    "            p_w_given_pos = pos_word_freq[word] / total_pos_words if word in pos_word_freq else 1e-10\n",
    "            p_w_given_neg = neg_word_freq[word] / total_neg_words if word in neg_word_freq else 1e-10\n",
    "\n",
    "            pmi_pos = np.log2(p_w_given_pos / p_word[word]) if p_word[word] > 0 else 0\n",
    "            pmi_neg = np.log2(p_w_given_neg / p_word[word]) if p_word[word] > 0 else 0\n",
    "\n",
    "            pmi_scores[word] = abs(pmi_pos - pmi_neg)\n",
    "\n",
    "    # Select top N words based on PMI score\n",
    "    selected_features = sorted(pmi_scores, key=pmi_scores.get, reverse=True)[:num_features_to_select]\n",
    "    return set(selected_features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_features_to_select = 5000\n",
    "feature_set = compute_pmi(train_dataframe, num_features_to_select)\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=feature_set)\n",
    "vectorizer.fit(train_dataframe['review'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2879999, 5000)\n",
      "(720000, 5000)\n",
      "(399999, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(train_X_selected.head())\\nprint (valid_X_selected.head)\\nprint (test_X_selected.head())'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_selected = feature_selector.transform(train_X)\n",
    "valid_X_selected = feature_selector.transform(valid_X)\n",
    "test_X_selected = feature_selector.transform(test_X)\n",
    "print (train_X_selected.shape)\n",
    "print (valid_X_selected.shape)\n",
    "print (test_X_selected.shape)\n",
    "'''print(train_X_selected.head())\n",
    "print (valid_X_selected.head)\n",
    "print (test_X_selected.head())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_X_selected = vectorizer.transform(train_dataframe['review'])\n",
    "valid_X_selected = vectorizer.transform(valid_dataframe['review'])\n",
    "test_X_selected = vectorizer.transform(test_dataframe['review'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore, I was just testing\n",
    "# print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 136)\t1\n",
      "  (0, 137)\t1\n",
      "  (0, 198)\t1\n",
      "  (0, 202)\t1\n",
      "  (0, 612)\t1\n",
      "  (0, 613)\t1\n",
      "  (0, 631)\t1\n",
      "  (0, 890)\t1\n",
      "  (0, 891)\t1\n",
      "  (0, 954)\t1\n",
      "  (0, 1613)\t1\n",
      "  (0, 1657)\t1\n",
      "  (0, 1691)\t1\n",
      "  (0, 1707)\t1\n",
      "  (0, 1969)\t1\n",
      "  (0, 2020)\t1\n",
      "  (0, 2051)\t1\n",
      "  (0, 2126)\t1\n",
      "  (0, 2422)\t1\n",
      "  (0, 2463)\t1\n",
      "  (0, 2660)\t1\n",
      "  (0, 3062)\t1\n",
      "  (0, 3111)\t1\n",
      "  (0, 3791)\t1\n",
      "  (0, 3916)\t1\n",
      "  (0, 3931)\t1\n",
      "  (0, 4010)\t1\n",
      "  (0, 4100)\t1\n",
      "  (0, 4239)\t1\n",
      "  (0, 4344)\t1\n",
      "  (0, 4770)\t1\n",
      "  (0, 4774)\t1\n"
     ]
    }
   ],
   "source": [
    "print(valid_X_selected[10])\n",
    "# print (test_X_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Logistic Regression - 90%\n",
    "model = LogisticRegression(C = 13, solver='liblinear')\n",
    "model.fit(train_X_selected, train_y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SVM - 88%\n",
    "# My own code, for \n",
    "# Asked chatgpt for help in implementing the code for SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define and train the SVM model\n",
    "model_svm = SVC(C=1.0, kernel='linear')  # You can change the kernel to 'rbf', 'poly', or 'sigmoid' if needed\n",
    "model_svm.fit(train_X_selected, train_y)\n",
    "train_y_hat = model_svm.predict(train_X_selected)\n",
    "accuracy = accuracy_score(train_y, train_y_hat)\n",
    "print('SVMs accuracy on training set:', accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Decision tree with 1000 features - 75%\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_dt = DecisionTreeClassifier(max_depth=28, random_state=42)  # You can tune max_depth\n",
    "model_dt.fit(train_X_selected, train_y)\n",
    "\n",
    "valid_y_hat = model_dt.predict(valid_X_selected)\n",
    "accuracy = accuracy_score(valid_y, valid_y_hat)\n",
    "print(f\"Decision Tree accuracy: {accuracy}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define XGBoost model\n",
    "''\n",
    "model_xgb = XGBClassifier(\n",
    "    n_estimators=600,        # Increase to compensate for lower learning rate\n",
    "    learning_rate=0.03,      # Reduce even further for better generalization\n",
    "    max_depth=6,             # Slightly deeper trees\n",
    "    min_child_weight=5,      # Require more samples per split (reduces overfitting)\n",
    "    subsample=0.75,          # Use 75% of data per tree (adds randomness)\n",
    "    colsample_bytree=0.75,   # Use 75% of features per tree (reduces overfitting)\n",
    "    gamma=0.2,               # Higher gamma to prevent unnecessary splits\n",
    "    reg_lambda=2,  # Correct parameter for L2 regularization,               # Stronger L2 regularization\n",
    "    alpha=1,                 # Adds L1 regularization\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb = XGBClassifier(\n",
    "    n_estimators=300, learning_rate=0.05, max_depth=4, \n",
    "    min_child_weight=5, subsample=0.8, colsample_bytree=0.8, gamma=0.2, \n",
    "    random_state=42\n",
    ")''\n",
    "\n",
    "model_xgb = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "# XGBoost accuracy on training set: 0.9373254990207109\n",
    "# XGBoost accuracy on validation set: 0.8731455242540423\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model_xgb.fit(train_X_selected, train_y)\n",
    "\n",
    "# Evaluate on training set\n",
    "train_y_hat = model_xgb.predict(train_X_selected)\n",
    "train_accuracy = accuracy_score(train_y, train_y_hat)\n",
    "print(f\"XGBoost accuracy on training set: {train_accuracy}\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "valid_y_hat = model_xgb.predict(valid_X_selected)\n",
    "valid_accuracy = accuracy_score(valid_y, valid_y_hat)\n",
    "print(f\"XGBoost accuracy on validation set: {valid_accuracy}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests, Multinomial Naive_bayes, Lightgbm, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Benchmark ---\n",
      "\n",
      "Training Logistic Regression (Baseline)...\n",
      "Logistic Regression (Baseline) Validation Accuracy: 90.3640%\n",
      "\n",
      "Training Multinomial Naive Bayes...\n",
      "Multinomial Naive Bayes Validation Accuracy: 87.4149%\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Validation Accuracy: 83.5056%\n",
      "\n",
      "Training LightGBM...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected np.float32 or np.float64, met type(int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_X_selected, train_y)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Make predictions on the unseen validation set\u001b[39;00m\n\u001b[1;32m     36\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(valid_X_selected)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/sklearn.py:1560\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1557\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1558\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1560\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m   1561\u001b[0m     X,\n\u001b[1;32m   1562\u001b[0m     _y,\n\u001b[1;32m   1563\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1564\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[1;32m   1565\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1566\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1567\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[1;32m   1568\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[1;32m   1569\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[1;32m   1570\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[1;32m   1571\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[1;32m   1572\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[1;32m   1573\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1574\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1575\u001b[0m )\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1050\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   1051\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m   1052\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[1;32m   1053\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1054\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1055\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1057\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1058\u001b[0m )\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:297\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    299\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/basic.py:3656\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[1;32m   3650\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[1;32m   3651\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3652\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[1;32m   3653\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3654\u001b[0m     )\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 3656\u001b[0m train_set\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/basic.py:2590\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2585\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[1;32m   2586\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[1;32m   2587\u001b[0m             )\n\u001b[1;32m   2588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[0;32m-> 2590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(\n\u001b[1;32m   2591\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   2592\u001b[0m         label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[1;32m   2593\u001b[0m         reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2594\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   2595\u001b[0m         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup,\n\u001b[1;32m   2596\u001b[0m         init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_score,\n\u001b[1;32m   2597\u001b[0m         predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[1;32m   2598\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_name,\n\u001b[1;32m   2599\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature,\n\u001b[1;32m   2600\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m   2601\u001b[0m         position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition,\n\u001b[1;32m   2602\u001b[0m     )\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[1;32m   2604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/basic.py:2183\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2174\u001b[0m     _safe_call(\n\u001b[1;32m   2175\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mLGBM_DatasetCreateFromFile(\n\u001b[1;32m   2176\u001b[0m             _c_str(\u001b[38;5;28mstr\u001b[39m(data)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2180\u001b[0m         )\n\u001b[1;32m   2181\u001b[0m     )\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix):\n\u001b[0;32m-> 2183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csr(data, params_str, ref_dataset)\n\u001b[1;32m   2184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsc_matrix):\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csc(data, params_str, ref_dataset)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/basic.py:2398\u001b[0m, in \u001b[0;36mDataset.__init_from_csr\u001b[0;34m(self, csr, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[1;32m   2397\u001b[0m ptr_indptr, type_ptr_indptr, __ \u001b[38;5;241m=\u001b[39m _c_int_array(csr\u001b[38;5;241m.\u001b[39mindptr)\n\u001b[0;32m-> 2398\u001b[0m ptr_data, type_ptr_data, _ \u001b[38;5;241m=\u001b[39m _c_float_array(csr\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m   2400\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m csr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m _MAX_INT32\n\u001b[1;32m   2401\u001b[0m csr_indices \u001b[38;5;241m=\u001b[39m csr\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/lightgbm/basic.py:766\u001b[0m, in \u001b[0;36m_c_float_array\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    764\u001b[0m         type_data \u001b[38;5;241m=\u001b[39m _C_API_DTYPE_FLOAT64\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected np.float32 or np.float64, met type(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown type(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected np.float32 or np.float64, met type(int64)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"--- Starting Benchmark ---\")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression (Baseline)\": LogisticRegression(C=12, solver='liblinear', random_state=42),\n",
    "    \n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \n",
    "    # Random Forest: An ensemble of decision trees. n_jobs=-1 is crucial for speed.\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        max_depth=50,       # Controls complexity to prevent overfitting\n",
    "        random_state=42, \n",
    "        n_jobs=-1           # Uses all available CPU cores for training\n",
    "    ),\n",
    "    \n",
    "    # LightGBM: A state-of-the-art Gradient Boosting Machine, known for top performance.\n",
    "    \"LightGBM\": lgb.LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# --- Run the benchmark ---\n",
    "results = {}\n",
    "\n",
    "# Re-using the feature matrices and labels from the cells above\n",
    "# (train_X_selected, valid_X_selected, train_y, valid_y)\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_X_selected, train_y)\n",
    "    \n",
    "    # Make predictions on the unseen validation set\n",
    "    predictions = model.predict(valid_X_selected)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracy = accuracy_score(valid_y, predictions)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} Validation Accuracy: {accuracy * 100:.4f}%\")\n",
    "\n",
    "# --- Final Results Summary ---\n",
    "print(\"\\n--- FINAL BENCHMARK RESULTS ---\")\n",
    "# Sort the results to find the best performing model\n",
    "for name, acc in sorted(results.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{name:<35} | Accuracy: {acc*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Logistic Regression (Baseline)...\n",
    "Logistic Regression (Baseline) Validation Accuracy: 90.3640%\n",
    "\n",
    "Training Multinomial Naive Bayes...\n",
    "Multinomial Naive Bayes Validation Accuracy: 87.4149%\n",
    "\n",
    "Training Random Forest...\n",
    "Random Forest Validation Accuracy: 83.5056%\n",
    "\n",
    "LightGBM (Gradient Boosting)        | Accuracy: 85.1663%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Converting data to float32 for LightGBM compatibility...\n",
      "\n",
      "--- Starting Model Training and Evaluation ---\n",
      "\n",
      "Training LightGBM (Gradient Boosting)...\n",
      "[LightGBM] [Info] Number of positive: 1440465, number of negative: 1439534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.439659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10000\n",
      "[LightGBM] [Info] Number of data points in the train set: 2879999, number of used features: 5000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500162 -> initscore=0.000647\n",
      "[LightGBM] [Info] Start training from score 0.000647\n",
      "✅ LightGBM (Gradient Boosting) Validation Accuracy: 85.1663%\n",
      "\n",
      "--- FINAL BENCHMARK RESULTS ---\n",
      "LightGBM (Gradient Boosting)        | Accuracy: 85.1663%\n"
     ]
    }
   ],
   "source": [
    "# Using float32 data type for lightgbm\n",
    "# LightGBM requires the data to be in float format (e.g., float32 or float64).\n",
    "# The CountVectorizer creates an integer matrix, so we convert it here.\n",
    "print(\">>> Converting data to float32 for LightGBM compatibility...\")\n",
    "train_X_selected = train_X_selected.astype('float32')\n",
    "valid_X_selected = valid_X_selected.astype('float32')\n",
    "\n",
    "models = {\"LightGBM (Gradient Boosting)\": lgb.LGBMClassifier(random_state=42)}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"\\n--- Starting Model Training and Evaluation ---\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(train_X_selected, train_y)\n",
    "    predictions = model.predict(valid_X_selected)\n",
    "    accuracy = accuracy_score(valid_y, predictions)\n",
    "    results[name] = accuracy\n",
    "    print(f\"✅ {name} Validation Accuracy: {accuracy * 100:.4f}%\")\n",
    "\n",
    "# --- 3. Final Results Summary ---\n",
    "print(\"\\n--- FINAL BENCHMARK RESULTS ---\")\n",
    "for name, acc in sorted(results.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{name:<35} | Accuracy: {acc*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "# Tokenization and Padding\n",
    "tokenizer = Tokenizer(num_words=3500, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_dataframe['review'])\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_dataframe['review'])\n",
    "valid_sequences = tokenizer.texts_to_sequences(valid_dataframe['review'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_dataframe['review'])\n",
    "\n",
    "max_length = 150  # Set max length for padding\n",
    "train_X = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\")\n",
    "valid_X = pad_sequences(valid_sequences, maxlen=max_length, padding=\"post\")\n",
    "test_X = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\")\n",
    "\n",
    "train_y = np.array(train_dataframe['label'])\n",
    "valid_y = np.array(valid_dataframe['label'])\n",
    "\n",
    "# Define LSTM model\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=3500, output_dim=128, input_length=max_length),\n",
    "    LSTM(64, return_sequences=True, recurrent_dropout=0.2),  # Adds recurrent dropout\n",
    "    Dropout(0.3),  # Increase dropout to prevent overfitting\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),  # Added dropout here too\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model_lstm.fit(\n",
    "    train_X, train_y,\n",
    "    validation_data=(valid_X, valid_y),\n",
    "    epochs=6,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "# Evaluate on validation set\n",
    "valid_loss, valid_accuracy = model_lstm.evaluate(valid_X, valid_y)\n",
    "print(f\"LSTM accuracy on validation set: {valid_accuracy}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' LSTM output\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 🚀 Predict on Test Data (Ensure Correct Shape)\n",
    "test_y_hat = (model_lstm.predict(test_X) > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# ✅ Debug: Check Sizes Before Saving\n",
    "print(f\"🔍 Predictions Generated: {len(test_y_hat)}\")\n",
    "print(f\"🔍 Test Data Size: {len(test_dataframe)}\")\n",
    "\n",
    "# ✅ Fix Length Mismatch\n",
    "if len(test_y_hat) > len(test_dataframe):\n",
    "    test_y_hat = test_y_hat[:len(test_dataframe)]  # Trim excess\n",
    "elif len(test_y_hat) < len(test_dataframe):\n",
    "    raise ValueError(f\"❌ ERROR: Predictions ({len(test_y_hat)}) are LESS than test data ({len(test_dataframe)})!\")\n",
    "\n",
    "# 🚀 Assign Predictions to DataFrame\n",
    "test_dataframe['label'] = test_y_hat\n",
    "\n",
    "# ✅ Set Save Path\n",
    "save_path = \"/Users/pacbook/Desktop/UNC/642 Data Mining/Homework - 2/csv_Code_Files/6000_lstm_predictions.csv\"\n",
    "\n",
    "# ✅ Ensure Save Directory Exists\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# 🚀 Save Predictions to CSV\n",
    "test_dataframe[['label']].to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"✅ Predictions saved successfully to: {save_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_y_hat = model.predict(train_X_selected)\n",
    "accuracy = accuracy_score(train_y, train_y_hat)\n",
    "print ('Logistic regression, accuracy on training set:', accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own code, ignore\n",
    "text = np.array([\"Amazing sucks\"])\n",
    "transform1 = vectorizer.transform(text)\n",
    "transform2 = feature_selector.transform(transform1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = transform1.toarray()\n",
    "array2 = transform2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1.toarray().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_indices = np.nonzero(array2)\n",
    "non_zero_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_values = array2[non_zero_indices]\n",
    "non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(transform2.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "valid_y_hat = model.predict(valid_X_selected)\n",
    "accuracy = accuracy_score(valid_y, valid_y_hat)\n",
    "print ('Logistic regression, accuracy on validation set:', accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "valid_y_hat = model_svm.predict(valid_X_selected)\n",
    "accuracy = accuracy_score(valid_y, valid_y_hat)\n",
    "print ('SVM accuracy on validation set:', accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After experimentation on the validation set: retrain the final model on all training data, and predict labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all_train_X = vectorizer.transform(dataframe['review'])\n",
    "all_train_X_selected = feature_selector.transform(all_train_X)\n",
    "all_train_y = dataframe['label'].to_numpy()\n",
    "\n",
    "model.fit(all_train_X_selected, all_train_y)\n",
    "test_y_hat = model.predict(test_X_selected)\n",
    "write_test_prediction(test_dataframe, test_y_hat, './logistic_regression.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_svm.fit(all_train_X_selected, all_train_y)\n",
    "test_y_hat = model_svm.predict(test_X_selected)\n",
    "write_test_prediction(test_dataframe, test_y_hat, './svm_predictions.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_y_hat = model_xgb.predict(test_X_selected)\n",
    "write_test_prediction(test_dataframe, test_y_hat, './xgboost_predictions.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_y_hat = (model_lstm.predict(test_X) > 0.5).astype(\"int32\")\n",
    "write_test_prediction(test_dataframe, test_y_hat, './lstm_predictions.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Ensure Predictions are in Correct Format\n",
    "test_y_hat = (model_lstm.predict(test_X) > 0.5).astype(\"int32\").flatten()  # Flatten removes brackets\n",
    "\n",
    "# 🚀 Save Predictions in Correct Format\n",
    "write_test_prediction(test_dataframe, test_y_hat, './40000lstm_predictions.csv')\n",
    "\n",
    "print(\"✅ Predictions saved in correct format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "print(os.getcwd())  # Get current working directory\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate what the model has learned and where it failed (A.K.A. error analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at learned parameters (for linear model: weight of each dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a mapping: word -> learned weight of this word\n",
    "feature_weight = {}\n",
    "for idx, feature in enumerate(selected_features):\n",
    "    feature_weight[feature] = model.coef_[0][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words correlated with positive sentiment (top ones)\n",
    "for k, v in sorted(feature_weight.items(), key = lambda x: x[1], reverse = True)[:20]:\n",
    "     print ('\"{}\"'.format(k), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words correlated with negative sentiments (top ones)\n",
    "for k, v in sorted(feature_weight.items(), key = lambda x: x[1], reverse = False)[:20]:\n",
    "     print ('\"{}\"'.format(k), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at how the model makes predictions on individual examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pick a set of examples from the validation set (we predicted scores for those).\n",
    "# We usually we don't pick from training data (since the good performance may be unrealistic).\n",
    "# We cannot do error analysis on test data （because no true target value is provided）."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_linear_prediction(df, model, idx2feature, X, y, y_hat, idx_list):\n",
    "    print('indices:', idx_list)\n",
    "    for idx in idx_list:\n",
    "        print ('==============', idx, '================')\n",
    "        print ('document:', df.iloc[idx]['review'])\n",
    "        print ('TRUE label:', df.iloc[idx]['label'])\n",
    "        print ('PRED label:', y_hat[idx])\n",
    "        \n",
    "        print ('\\nPRED breakdown:')\n",
    "        print ('\\tINTERCEPT', model.intercept_)\n",
    "        if X[idx, :].nnz == 0:\n",
    "            print ('\\tFEATURE', '[EMPTY]')\n",
    "        else:\n",
    "            sp_row = X[idx, :]\n",
    "            for i in range(sp_row.getnnz()): # looping over a row in sparse matrix \n",
    "                feature_value = sp_row.data[i]\n",
    "                feature_dim = sp_row.indices[i]\n",
    "                print ('\\tFEATURE', idx2feature[feature_dim], ':', feature_value, '*', model.coef_[0][feature_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a dictionary mapping: feature index -> word\n",
    "idx2feature = dict([(idx, feature) for idx, feature in enumerate(selected_features)])\n",
    "\n",
    "# look at data with prediction error\n",
    "error_indices  = [i for i in range(len(valid_y_hat)) if valid_y_hat[i] != valid_y[i]]\n",
    "explain_linear_prediction(valid_dataframe, model, idx2feature, valid_X_selected, valid_y, valid_y_hat, np.random.choice(error_indices, size = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
